# Reproducibility Code for IEEE SPL Submission: "Sparsity-Constrained NMF Tokenization for Interpretable Medical Signal Classification"

This repository contains the Python scripts required to reproduce the experiments, tables, and figures for the paper.

## 1. Setup
* **Dataset:** PhysioNet 2016 Challenge Dataset (3,541 phonocardiogram recordings).
* **Environment:** Python 3.10+ (Tested on Google Colab, NVIDIA T4 GPU).
* **Dependencies:** `tensorflow`, `librosa`, `numpy`, `pandas`, `scikit-learn`, `matplotlib`, `opencv-python`.

## 2. Core Methodology
The proposed method follows a two-stage pipeline:
1. **Stage 1:** Sparsity-constrained NMF decomposes spectrograms into physically meaningful frequency atoms.
2. **Stage 2:** Random Forest classifier operates on temporal-averaged atom activations (8-dimensional features).

## 3. Quantitative Results (Table I)
To generate the accuracy and F1-scores for the comparative study:

* **Proposed Method (NMF + Random Forest):** Run `nmf_classification_baseline.py`
    * *Outputs:* Accuracy (82.2%), F1-Score (0.43), Spectral Concentration (0.65).
    * *Note:* This script extracts NMF atom features and trains the Random Forest classifier.
* **CNN Baseline:** Run `cnn_baseline_study.py`
    * *Outputs:* CNN Accuracy (90.6%), F1-Score (0.80).
* **ViT Baseline:** Run `vit_baseline_study.py`
    * *Outputs:* Standard Vision Transformer Accuracy (86.2%), F1-Score (0.68).
* **HPSS Baseline:** Run `hpss_baseline_study.py`
    * *Outputs:* Harmonic-Percussive Source Separation Accuracy (88.4%), F1-Score (0.74).
* **Standard NMF (Unconstrained):** Run `nmf_classification_baseline.py` (with `alpha_H=0`)
    * *Outputs:* Unconstrained NMF Accuracy (76.5%), F1-Score (0.38).

## 4. Signal Processing Metrics (Section II-C)
The following metrics quantify the physical interpretability of NMF atoms:

* **Spectral Concentration:** Ratio of energy in clinical bands (20-400 Hz) to total energy.
* **Atom Sparsity Index:** Hoyer sparsity measure of activation matrix $H$.
* **Map Sparsity:** Hoyer sparsity of diagnostic heatmaps (quantifies explanation precision).

These are computed automatically within `nmf_experiments.py`.

## 5. Interpretability Analysis (Section IV-D)
To reproduce the "Map Sparsity" comparison (CNN Grad-CAM: 0.13 vs. Proposed: 0.86):

1. **Generate CNN Heatmap:** Run `cnn_rebuild_and_gradcam.py`
    * *Action:* Trains CNN with Functional API and generates Grad-CAM visualization.
    * *Output:* Saves `gradcam_comparison.png`.
2. **Calculate Sparsity Scores:** Run `compare_explanation_sparsity.py`
    * *Action:* Computes Hoyer sparsity for both Grad-CAM heatmaps and NMF atom reconstructions.
    * *Output:* Prints Map Sparsity values for Table I.

## 6. Figures
The following scripts generate the figures used in the manuscript:

* **Fig. 1: Robustness of Learned Atoms vs. Noise** (`Fig2_Robustness.png`)
    * *Source:* Generated by `nmf_experiments.py`.
    * *Description:* Cosine similarity of atoms under AWGN at 0-25 dB SNR.
    * *Key Result:* Sparsity-constrained NMF maintains >0.55 stability at 0 dB vs. standard NMF.

* **Fig. 2: Diagnostic Heatmap Visualization** (`Fig3_Heatmap.png`)
    * *Source:* Generated by `nmf_experiments.py`.
    * *Description:* (a) Input spectrogram, (b) Atom #7 heatmap isolating S1/S2 heart sounds.
    * *Key Result:* Demonstrates physically grounded interpretability.

* **Fig. 3: Ablation Study on NMF Rank $K$** (`Fig4_Ablation.png`)
    * *Source:* Generated by `nmf_ablation_study.py`.
    * *Description:* Elbow plot showing reconstruction error vs. sparsity trade-off.
    * *Key Result:* Optimal rank identified at $K=8$.

## 7. Execution Instructions

### Step 1: Mount Google Drive (if using Colab)
```python
from google.colab import drive
drive.mount('/content/drive')
```

### Step 2: Set Dataset Path
Ensure the PhysioNet 2016 dataset is located at:
```
/content/drive/MyDrive/PhysioNet2016/
```
All scripts use this default path in the `CONF` dictionary.

### Step 3: Run Experiments
Execute scripts in the following order for full reproducibility:

1. **Extract NMF features and train classifier:**
   ```bash
   python nmf_classification_baseline.py
   ```

2. **Train baseline models:**
   ```bash
   python cnn_baseline_study.py
   python vit_baseline_study.py
   python hpss_baseline_study.py
   ```

3. **Generate interpretability metrics:**
   ```bash
   python cnn_rebuild_and_gradcam.py
   python compare_explanation_sparsity.py
   ```

4. **Create figures:**
   ```bash
   python nmf_experiments.py  # Generates Fig 1 & 2
   python nmf_ablation_study.py                # Generates Fig 3
   ```

## 8. Expected Runtime
* **Full dataset (n=3,541):** 45 minutes total on NVIDIA T4 GPU.
* **Per-script breakdown:**
    * NMF feature extraction: 15 minutes
    * CNN training: 10 minutes
    * ViT training: 15 minutes
    * HPSS processing: 5 minutes

## 9. Key Implementation Details

### NMF Configuration
```python
NMF(n_components=8,           # K atoms
    solver='mu',              # Multiplicative update
    beta_loss='kullback-leibler',  # KL divergence
    alpha_H=0.1,              # Sparsity penalty Î»
    max_iter=500,             # Convergence iterations
    random_state=42)
```

### Random Forest Configuration
```python
RandomForestClassifier(n_estimators=100, 
                      random_state=42)
```

### Train/Test Split
* 70% training, 30% testing
* Fixed random seed (42) for reproducibility
* No cross-validation (single split)

## 10. Troubleshooting

**Issue:** `ConvergenceWarning` during NMF
* **Solution:** Increase `max_iter` in NMF configuration (already set to 500 in code).

**Issue:** "No files found" error
* **Solution:** Verify dataset path in `CONF['BASE_PATH']` matches your directory structure.

**Issue:** Keras 3 compatibility errors
* **Solution:** Ensure TensorFlow 2.19.0+ and Keras 3.10.0+ are installed (included in requirements).

